{"cells":[{"cell_type":"markdown","metadata":{"id":"O4vFspE6wAC_"},"source":["<h1 align=\"center\">LAB1_S3. Static word-embeddings for text representation</h1>\n","\n","<h3 style=\"display:block; margin-top:5px;\" align=\"center\">Natural Language and Information Retrieval</h3>\n","<h3 style=\"display:block; margin-top:5px;\" align=\"center\">Degree in Data Science</h3>\n","<h3 style=\"display:block; margin-top:5px;\" align=\"center\">2024-2025</h3>    \n","<h3 style=\"display:block; margin-top:5px;\" align=\"center\">ETSInf. Universitat Polit√®cnica de Val√®ncia</h3>\n","<br>"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29691,"status":"ok","timestamp":1741038445140,"user":{"displayName":"MRGXD","userId":"05360451841437219774"},"user_tz":-60},"id":"sE8J46kCONUy","outputId":"fabf8ba3-f40a-49f5-abce-65cf2adebe39"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Collecting fasttext-wheel\n","  Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting pybind11>=2.2 (from fasttext-wheel)\n","  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel) (75.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel) (1.26.4)\n","Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybind11, fasttext-wheel\n","Successfully installed fasttext-wheel-0.9.2 pybind11-2.13.6\n"]}],"source":["#Installing Gensim library\n","!pip install -U gensim\n","!pip install -U nltk\n","!pip install -U fasttext-wheel"]},{"cell_type":"markdown","metadata":{"id":"t4IdboIqwADB"},"source":["## Some libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9750,"status":"ok","timestamp":1741038454883,"user":{"displayName":"MRGXD","userId":"05360451841437219774"},"user_tz":-60},"id":"4iBKniCGOQ5X","outputId":"56bd0d0d-6283-4b01-de2d-71aa855587fc"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import fasttext.util\n","import gensim.downloader as api\n","from gensim.models.keyedvectors import KeyedVectors\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import numpy as np\n","import pandas as pd\n","import re\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","nltk.download(\"punkt_tab\")#nltk.download(\"punkt\")\n","nltk.download('stopwords')"]},{"cell_type":"markdown","metadata":{"id":"cJzPaO1pwADD"},"source":["## Load both corpora"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":122034,"status":"error","timestamp":1741038576922,"user":{"displayName":"MRGXD","userId":"05360451841437219774"},"user_tz":-60},"id":"od0PeFAUwADD","colab":{"base_uri":"https://localhost:8080/","height":356},"outputId":"888b889a-e31e-44b4-8256-af1163e24770"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-37f2c6e4ae22>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# OR USING Google colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m df = {\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"english\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/LNR/EXIST2024_EN_examples.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["path_english = \"EXIST2024_EN_examples.csv\"\n","path_spanish = \"EXIST2024_ES_examples.csv\"\n","\n","#df = {\n","#    \"english\": pd.read_csv(path_english, sep=\"\\t\"),\n","#    \"spanish\": pd.read_csv(path_spanish, sep=\"\\t\")\n","#}\n","\n","# OR USING Google colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","df = {\n","    \"english\": pd.read_csv(\"/content/drive/MyDrive/LNR/EXIST2024_EN_examples.csv\", sep=\"\\t\"),\n","    \"spanish\": pd.read_csv(\"/content/drive/MyDrive/LNR/EXIST2024_ES_examples.csv\", sep=\"\\t\")\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"koDhhLFYwADE"},"source":["##¬†Preprocess and tokenize the corpora:\n","\n","- remove URLs\n","- remove hashtags\n","- remove users\n","- lowercase\n","- tokenize (using _word_tokenize_)\n","- remove stopwords (using nltk stopwords)\n","\n","Note: tokenization and stopword removal are language-dependent."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1824,"status":"ok","timestamp":1741034875654,"user":{"displayName":"Marc Siquier","userId":"06433603318975963961"},"user_tz":-60},"id":"WIc7OLcpwADF","outputId":"cdd33880-71a6-488b-c031-45fa17f8c4d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Hola, mi nombre es Antonio, ¬øtodo bien? https://www.upv.es @paquita', 'Hi! my name is Peter']\n","[['hola', ',', 'nombre', 'antonio', ',', '¬øtodo', 'bien', '?'], ['hi', '!', 'my', 'name', 'is', 'peter']]\n","[['hola', ',', 'mi', 'nombre', 'es', 'antonio', ',', '¬øtodo', 'bien', '?'], ['hi', '!', 'name', 'peter']]\n"]}],"source":["# Info: nltk.tokenize.word_tokenize(text, language='english', preserve_line=False)\n","\n","web_re = re.compile(r\"https?:\\/\\/[^\\s]+\", re.U)\n","user_re = re.compile(r\"(@\\w+\\-?(?:\\w+)?)\", re.U)\n","hashtag_re = re.compile(r\"(#\\w+\\-?(?:\\w+)?)\", re.U)\n","\n","stopw = {\n","    \"english\": nltk.corpus.stopwords.words(\"english\"),\n","    \"spanish\": nltk.corpus.stopwords.words(\"spanish\")\n","}\n","\n","def preprocess(text):\n","    text = web_re.sub(\"\", text)  # Remove URLs\n","    text = user_re.sub(\"\", text)  # Remove user mentions\n","    text = hashtag_re.sub(\"\", text)  # Remove hashtags\n","    text = text.lower()  # Convert to lowercase\n","    return text\n","\n","def tokenize(text_list, lang=\"english\"):\n","    #¬†COMPLETE\n","    token_list = []\n","    for text in text_list:\n","        cleaned_text = preprocess(text)\n","        tokens = word_tokenize(cleaned_text, language=lang)\n","        filtered_tokens = [word for word in tokens if word not in stopw[lang]]\n","        token_list.append(filtered_tokens)\n","    return token_list\n","\n","tokenized_text = {\n","    \"english\": tokenize(df[\"english\"][\"text\"], \"english\"),\n","    \"spanish\": tokenize(df[\"spanish\"][\"text\"], \"spanish\")\n","}\n","\n","t = [\"Hola, mi nombre es Antonio, ¬øtodo bien? https://www.upv.es @paquita\", \"Hi! my name is Peter\"]\n","print(t)\n","print(tokenize(t, \"spanish\"))\n","print(tokenize(t, \"english\"))"]},{"cell_type":"markdown","metadata":{"id":"XUup9ejVwADF"},"source":["##¬†Text representation using static embeddings\n","\n","ENGLISH\n","\n","- word2vec-google-news-300 (using Gemini)\n","- fasttext-wiki-news-subwords-300 (using Gemini)\n","- glove-wiki-gigaword-300 (using Gemini)\n","\n","SPANISH\n","- Fasttext (https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz) (using Gemini)"]},{"cell_type":"markdown","metadata":{"id":"wClIBsfEwADG"},"source":["###¬†Load the models"]},{"cell_type":"code","source":["#from google.colab import drive\n","#import gensim.downloader as api\n","\n","# Montar Google Drive\n","#drive.mount('/content/drive')\n","\n","# Definir rutas para guardar los modelos\n","#base_path = \"/content/drive/MyDrive/gensim_models/\"\n","#word2vec_path = base_path + \"word2vec-google-news-300.model\"\n","#fasttext_path = base_path + \"fasttext-wiki-news-subwords-300.model\"\n","#glove_path = base_path + \"glove-wiki-gigaword-300.model\"\n","\n","# Descargar y guardar modelos\n","#word2vec = api.load(\"word2vec-google-news-300\")\n","#word2vec.save(word2vec_path)\n","\n","#fasttext_en = api.load(\"fasttext-wiki-news-subwords-300\")\n","#fasttext_en.save(fasttext_path)\n","\n","#glove = api.load(\"glove-wiki-gigaword-300\")\n","#glove.save(glove_path)\n","\n","#print(\"Modelos guardados en Google Drive.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VkEBHaHfB0F","executionInfo":{"status":"ok","timestamp":1741031025552,"user_tz":-60,"elapsed":541622,"user":{"displayName":"Marc Siquier","userId":"06433603318975963961"}},"outputId":"433946e9-5a4b-4c13-a810-9dc13d7ba873"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Modelos guardados en Google Drive.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","from gensim.models import KeyedVectors\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Definir rutas de los modelos\n","base_path = \"/content/drive/MyDrive/gensim_models/\"\n","word2vec_path = base_path + \"word2vec-google-news-300.model\"\n","fasttext_path = base_path + \"fasttext-wiki-news-subwords-300.model\"\n","glove_path = base_path + \"glove-wiki-gigaword-300.model\"\n","\n","# Cargar modelos desde el almacenamiento local\n","word2vec = KeyedVectors.load(word2vec_path)\n","fasttext_en = KeyedVectors.load(fasttext_path)\n","glove = KeyedVectors.load(glove_path)\n","\n","es_model = KeyedVectors.load_word2vec_format(\"/content/cc.es.300.bin.gz\", binary=True)\n","\n","print(\"Modelos cargados desde Google Drive.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Is3th6abfPLP","executionInfo":{"status":"error","timestamp":1741035833333,"user_tz":-60,"elapsed":30688,"user":{"displayName":"Marc Siquier","userId":"06433603318975963961"}},"outputId":"c68a0b35-46ba-4955-d523-c10b1d0754ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/cc.es.300.bin.gz'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-5809ee5c42d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mes_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/cc.es.300.bin.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Modelos cargados desde Google Drive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \"\"\"\n\u001b[0;32m-> 1719\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1720\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     filename = (\n\u001b[1;32m    226\u001b[0m         \u001b[0mbinary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mscheme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sniff_scheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0msubmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mfobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smart_open/local_file.py\u001b[0m in \u001b[0;36mopen_uri\u001b[0;34m(uri_as_string, mode, transport_params)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mparsed_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uri_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/cc.es.300.bin.gz'"]}]},{"cell_type":"markdown","metadata":{"id":"UiVNuQWDwADG"},"source":["### Compute static word-embeddings representation of the tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jOfurEycwADH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741031220528,"user_tz":-60,"elapsed":748,"user":{"displayName":"Marc Siquier","userId":"06433603318975963961"}},"outputId":"836c53cc-29c9-4a65-b458-8a7d1cd4a2a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["[ 0.03984649  0.02089928 -0.03820169  0.12103482 -0.03136365  0.04779\n","  0.00409567 -0.04767267  0.07529423  0.05294195  0.01294156 -0.09585624\n"," -0.05405978  0.01406966 -0.0938868   0.04490925  0.03281166  0.12748166\n","  0.08025478 -0.12434545 -0.00841233  0.0613135  -0.0060046  -0.00787985\n","  0.05632493 -0.04291102 -0.08166083  0.06243212  0.09708378 -0.04894967\n","  0.03260119 -0.00482809 -0.02081483 -0.00529954  0.03326291  0.05588926\n","  0.05469776 -0.01033388  0.06848986  0.10389762  0.08990268 -0.06543942\n","  0.13988416  0.00971301 -0.02455087 -0.00292337 -0.06240529 -0.04385902\n"," -0.02660817  0.02828138 -0.07819656  0.06540759  0.020592   -0.01371818\n","  0.03399448  0.00438822 -0.02529065 -0.07915207  0.02505388 -0.1243102\n","  0.05248392  0.04191945 -0.09331881 -0.02962283  0.06362178  0.01116312\n"," -0.05182135  0.02382213 -0.03370824  0.04812833  0.03661162  0.01473789\n","  0.07373902  0.01100317 -0.19417914 -0.03608651  0.0338219   0.07401565\n","  0.04823672  0.06193385 -0.00915212 -0.03922666  0.02204112  0.01734595\n"," -0.06186439 -0.0026166  -0.07582671  0.18679073  0.10081535  0.0434444\n","  0.01760496 -0.0071348  -0.05044661 -0.09877172 -0.05754142 -0.00818502\n","  0.08893822  0.02200238 -0.0147121  -0.03302107 -0.13045318 -0.06072788\n","  0.06199856 -0.00083765 -0.01482944 -0.081267   -0.04836457 -0.04529052\n","  0.02319967 -0.05453123 -0.02286503 -0.01043701 -0.00098077 -0.03794203\n","  0.05537204 -0.02644085  0.03179958 -0.02786044  0.11071777 -0.00873855\n"," -0.06719865  0.03749242 -0.0357645   0.07325902  0.03693258 -0.05207919\n"," -0.01392654 -0.03237744  0.00256979 -0.0265966  -0.07034197 -0.19212394\n"," -0.13432786  0.00304965 -0.04525362 -0.00023572  0.06257366  0.05197038\n"," -0.01196111  0.10643795  0.082921   -0.01840315  0.00816608 -0.04573638\n"," -0.00388706  0.07029356 -0.11344962 -0.07815226 -0.02327294 -0.06541075\n","  0.07386411  0.05619602 -0.06186229  0.02433829 -0.01092898 -0.01073587\n"," -0.01461897 -0.11151965 -0.09672178 -0.01157248 -0.04198061  0.08464366\n","  0.03721066  0.06340079  0.05789513 -0.08238378  0.07275391 -0.06131192\n"," -0.00586773 -0.06463202 -0.10586653 -0.05124533  0.01580074 -0.04263832\n"," -0.07833257  0.00436862  0.09188961 -0.05132951 -0.04268883  0.08233853\n"," -0.0477898  -0.01786271  0.03670423  0.03893043  0.02120656 -0.02070986\n"," -0.04640356  0.04184039  0.09762258  0.00052196  0.01696712  0.05146737\n","  0.0018642   0.0003278   0.01727768  0.03974651  0.03299055 -0.07996026\n"," -0.08931627 -0.02230598  0.00044829  0.07454708 -0.08154928 -0.02301446\n","  0.00270238 -0.00686277 -0.06789063  0.01355507  0.00886582 -0.0196007\n"," -0.0322434   0.02928109  0.00419143  0.00629241 -0.06781006 -0.01838631\n","  0.04800836  0.03107281 -0.08406225  0.01434642 -0.04088303 -0.01041491\n"," -0.03370193  0.00349374  0.10523513 -0.00310648  0.01274582  0.01604067\n"," -0.02805407 -0.01578548 -0.01773492 -0.05226925 -0.04577426  0.04732119\n","  0.03035815 -0.03969456  0.01068352 -0.06074919  0.00109758  0.06625682\n","  0.07403893  0.03529831 -0.02728903 -0.06228717 -0.02258801  0.0092784\n"," -0.00368789  0.10325044  0.01406334 -0.08872249 -0.01857047  0.08255899\n","  0.12988492  0.12243231  0.03614018 -0.04118189  0.03407761 -0.01152512\n"," -0.04118295 -0.00976826 -0.02128654  0.04191011 -0.03349357  0.00551421\n"," -0.00521364  0.0875644  -0.07564571 -0.06084416 -0.06644834 -0.04015903\n","  0.02656581  0.06474567  0.08518929  0.05300588  0.04379851 -0.03427492\n"," -0.0251943  -0.11127761 -0.08813371  0.04209953  0.03798307 -0.07327902\n","  0.0381325   0.07910419  0.02201199  0.01511968 -0.06643203  0.04368881\n","  0.07479753  0.09160167 -0.01375396  0.07866971 -0.14480801  0.02904221\n"," -0.06066487  0.00689789  0.00138908 -0.05579495  0.03613413  0.02156856]\n"]}],"source":["def gensim_sentence_rep(tokens, model):\n","    \"\"\"\n","    Compute the word-embedding representation of a list of tokens by averaging\n","        the representations of each word\n","    \"\"\"\n","    avg_vec = np.zeros(model.vector_size)\n","    total_w = 0\n","\n","    for word in tokens:\n","        if word in model:\n","            avg_vec += model[word]\n","            total_w += 1\n","\n","    if total_w == 0:\n","        return avg_vec  # Evita la divisi√≥n por cero\n","    return avg_vec / total_w\n","\n","# Apply \"gensim_sentence_rep\"\n","# COMPLETE\n","sentence_vectors = {\n","    \"word2vec\": [gensim_sentence_rep(tokens, word2vec) for tokens in tokenized_text[\"english\"]],\n","    \"fasttext\": [gensim_sentence_rep(tokens, fasttext_en) for tokens in tokenized_text[\"english\"]],\n","    \"glove\": [gensim_sentence_rep(tokens, glove) for tokens in tokenized_text[\"english\"]]\n","}\n","\n","# Ejemplo de salida\n","print(sentence_vectors[\"word2vec\"][0])\n"]},{"cell_type":"markdown","metadata":{"id":"RautX5QvwADH"},"source":["##¬†Compute cosine similarities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkBr3hzkwADH"},"outputs":[],"source":["def compute_cosine_similarities(vectors):\n","    return cosine_similarity(vectors)\n","\n","cosine_similarities = {\n","    \"word2vec\": compute_cosine_similarities(sentence_vectors[\"word2vec\"]),\n","    \"fasttext\": compute_cosine_similarities(sentence_vectors[\"fasttext\"]),\n","    \"glove\": compute_cosine_similarities(sentence_vectors[\"glove\"])\n","}\n","\n","def find_most_similar_optimized(sim_matrix, df, label_col, label):\n","    df_filtered = df[df[label_col] == label]\n","    indices = df_filtered.index.tolist()\n","\n","    if len(indices) < 2:\n","        return (None, None), -1  # Si hay menos de dos elementos, no se puede calcular la similitud\n","\n","    max_sim = -1\n","    best_pair = (None, None)\n","\n","    for i in range(len(indices)):\n","        for j in range(i + 1, len(indices)):\n","            sim = sim_matrix[indices[i], indices[j]]\n","            if sim > max_sim:\n","                max_sim = sim\n","                best_pair = (df_filtered.iloc[i]['id'], df_filtered.iloc[j]['id'])\n","\n","    return best_pair, max_sim"]},{"cell_type":"markdown","metadata":{"id":"R4EDMZpmwADH"},"source":["## Show results"]},{"cell_type":"code","source":["for name, sim_matrix in cosine_similarities.items():\n","    print(f\"======================\\n{name} \\n----------------------\")\n","    for label in ['NO', 'YES']:\n","        best_pair, similarity = find_most_similar_optimized(sim_matrix, df[\"english\"], \"label\", label)\n","        if best_pair[0] is not None:\n","            print(f\"Label: {label} \\nTweets IDs: {best_pair} \\nSimilarity: {similarity:.4f}\")\n","            print(f\"Tweets: \\n \\t1: {df['english'].loc[df['english']['id'] == best_pair[0], 'text'].values[0]} \\n \\t2: {df['english'].loc[df['english']['id'] == best_pair[1], 'text'].values[0]}\")\n","        if label == \"NO\":\n","            print(\"----------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vaMiNpdlwUG","executionInfo":{"status":"ok","timestamp":1741031945774,"user_tz":-60,"elapsed":2650,"user":{"displayName":"Marc Siquier","userId":"06433603318975963961"}},"outputId":"34c1a7b5-d567-4e45-e64e-35179ff84106"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================\n","word2vec \n","----------------------\n","Label: NO \n","Tweets IDs: (201173, 201177) \n","Similarity: 0.9444\n","Tweets: \n"," \t1: @BLEEDTHISWAY replay free woman breebylon &gt;&gt;&gt; Flop this way \n"," \t2: replay&gt;alice&gt;babylon&gt;free woman https://t.co/WCEqeUxdtC\n","----------------------\n","Label: YES \n","Tweets IDs: (201621, 201637) \n","Similarity: 0.9614\n","Tweets: \n"," \t1: @WeaponizedRage Aerosmith in 1987: \"Dude looks like a lady\" \n"," \t2: Dude does not look like a lady! https://t.co/C62JmKSzy0\n","======================\n","fasttext \n","----------------------\n","Label: NO \n","Tweets IDs: (201173, 201177) \n","Similarity: 0.9898\n","Tweets: \n"," \t1: @BLEEDTHISWAY replay free woman breebylon &gt;&gt;&gt; Flop this way \n"," \t2: replay&gt;alice&gt;babylon&gt;free woman https://t.co/WCEqeUxdtC\n","----------------------\n","Label: YES \n","Tweets IDs: (201235, 201978) \n","Similarity: 0.9716\n","Tweets: \n"," \t1: in the living room, all strocking to porn. all4guys+host had fucked me. 1st, straight,had cum in cumhole. I was so surprised&amp; pleased.even if short &amp;light, was so hot be gangbanged w/o knowing, blindfolded, w straight men &amp;bred by straight man!A108M31 #chastity #cumdump #gangbang \n"," \t2: @TabitaSurge Ha! My English teacher did similar in year 7 when I commented \"b/c the patriarchy was, still is &amp; always will be, bullshit\" in discussion about Portia/ Merchant of Venice. She loaned me books &amp; it was through her I discovered Wollstonecraft, Dworkin, Butler, Lorde and more...\n","======================\n","glove \n","----------------------\n","Label: NO \n","Tweets IDs: (201173, 201177) \n","Similarity: 0.9690\n","Tweets: \n"," \t1: @BLEEDTHISWAY replay free woman breebylon &gt;&gt;&gt; Flop this way \n"," \t2: replay&gt;alice&gt;babylon&gt;free woman https://t.co/WCEqeUxdtC\n","----------------------\n","Label: YES \n","Tweets IDs: (200204, 200217) \n","Similarity: 0.9565\n","Tweets: \n"," \t1: @lkmeenha we can‚Äôt even have a day without women making it about themselves üôÑ \n"," \t2: @BigDILF01 Can‚Äôt go a day without women womening\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"}},"nbformat":4,"nbformat_minor":0}