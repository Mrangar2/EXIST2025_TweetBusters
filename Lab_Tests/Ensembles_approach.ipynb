{"cells":[{"cell_type":"markdown","id":"e129e32c","metadata":{"id":"e129e32c"},"source":["# Ensembles approach"]},{"cell_type":"code","source":["COLAB =True # IF YOU USE GOOGLE COLAB -> COLAB = True\n","PIP = True # IF YOU NEED INSTALL LIBRARIES -> PIP = True"],"metadata":{"id":"OSRNrkEDDaES"},"id":"OSRNrkEDDaES","execution_count":null,"outputs":[]},{"cell_type":"code","source":["if PIP:\n","    !pip install transformers --upgrade\n","    !pip install datasets accelerate\n","    !pip install evaluate\n","    !pip install -U PyEvALL\n","\n","    !pip install torch\n","    !pip install numpy\n","    !pip install pandas\n","    !pip install scikit-learn\n","    !pip install optuna"],"metadata":{"id":"f_CgejvPDgIZ"},"id":"f_CgejvPDgIZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"QVf-N84IDk6W"},"id":"QVf-N84IDk6W"},{"cell_type":"code","source":[],"metadata":{"id":"fPIzKGJXDmde"},"id":"fPIzKGJXDmde","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","if COLAB is True:\n","  from google.colab import drive\n","  drive.mount('/content/drive',force_remount=True)\n","  base_path = \"/content/drive/MyDrive/EXISTS2025_TweetBusters\"\n","  library_path = base_path + \"/Functions\"\n","else:\n","  base_path = Path.cwd().parent\n","  library_path = base_path / \"Functions\"\n","\n","\n","\n","sys.path.insert(0, str(library_path))\n","from readerEXIST2025_2 import EXISTReader"],"metadata":{"id":"A43ZuBK3DmOV"},"id":"A43ZuBK3DmOV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import importlib.util\n","import sys\n","import inspect\n","\n","functions_path = library_path\n","\n","for filename in os.listdir(functions_path):\n","    if filename.endswith(\".py\") and not filename.startswith(\"__\"):\n","        module_name = filename[:-3]\n","        file_path = os.path.join(functions_path, filename)\n","\n","        # Cargar el módulo\n","        spec = importlib.util.spec_from_file_location(module_name, file_path)\n","        module = importlib.util.module_from_spec(spec)\n","        spec.loader.exec_module(module)\n","\n","        # Extraer todas las funciones del módulo y cargarlas al espacio global\n","        for name, func in inspect.getmembers(module, inspect.isfunction):\n","            globals()[name] = func  # o locals()[name] si estás dentro de una función"],"metadata":{"id":"xF39IVtIDqJ7"},"id":"xF39IVtIDqJ7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# path to the dataset, adapt this path wherever you have the dataset\n","dataset_path = os.path.join(base_path, \"Dataset/EXIST_2025_Dataset_V0.3/\")\n","\n","file_train = os.path.join(dataset_path, \"EXIST2025_training.json\")\n","file_dev = os.path.join(dataset_path, \"EXIST2025_dev.json\")\n","file_test = os.path.join(dataset_path, \"EXIST2025_test_clean.json\")\n","\n","\n","reader_train = EXISTReader(file_train)\n","reader_dev = EXISTReader(file_dev)\n","reader_test = EXISTReader(file_test)\n","\n","\n","EnTrainTask1, EnDevTask1, EnTestTask1 = reader_train.get(lang=\"EN\", subtask=\"1\"), reader_dev.get(lang=\"EN\", subtask=\"1\"), reader_test.get(lang=\"EN\", subtask=\"1\")\n","EnTrainTask2, EnDevTask2, EnTestTask2 = reader_train.get(lang=\"EN\", subtask=\"2\"), reader_dev.get(lang=\"EN\", subtask=\"2\"), reader_test.get(lang=\"EN\", subtask=\"2\")\n","EnTrainTask3, EnDevTask3, EnTestTask3 = reader_train.get(lang=\"EN\", subtask=\"3\"), reader_dev.get(lang=\"EN\", subtask=\"3\"), reader_test.get(lang=\"EN\", subtask=\"3\")\n","\n","\n","SpTrainTask1, SpDevTask1, SpTestTask1  = reader_train.get(lang=\"ES\", subtask=\"1\"), reader_dev.get(lang=\"ES\", subtask=\"1\"), reader_test.get(lang=\"ES\", subtask=\"1\")\n","SpTrainTask2, SpDevTask2, SpTestTask2  = reader_train.get(lang=\"ES\", subtask=\"2\"), reader_dev.get(lang=\"ES\", subtask=\"2\"), reader_test.get(lang=\"ES\", subtask=\"2\")\n","SpTrainTask3, SpDevTask3, SpTestTask3  = reader_train.get(lang=\"ES\", subtask=\"3\"), reader_dev.get(lang=\"ES\", subtask=\"3\"), reader_test.get(lang=\"ES\", subtask=\"3\")\n"],"metadata":{"id":"4uTCm5j7DoH7"},"id":"4uTCm5j7DoH7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import tempfile\n","import ast\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.metrics import f1_score\n","\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","from pyevall.evaluation import PyEvALLEvaluation\n","from pyevall.metrics.metricfactory import MetricFactory\n","from pyevall.reports.reports import PyEvALLReport\n","from pyevall.utils.utils import PyEvALLUtils\n"],"metadata":{"id":"Q47m8TzeDi3H"},"id":"Q47m8TzeDi3H","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"87b785bd","metadata":{"id":"87b785bd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score\n","from Tasks_LoRA_Pipelines import sexism_classification_pipeline_task1_LoRA  # para Task 1\n","from Tasks_LoRA_Pipelines import sexism_classification_pipeline_task2_LoRA  # para Task 2\n","from readerEXIST2025 import EXISTReader\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def get_probs(model_ckpt_path, texts, max_length=128, batch_size=32):\n","    \"\"\"Carga un modelo guardado y devuelve un array (N, C) de probabilidades.\"\"\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_ckpt_path)\n","    model = AutoModelForSequenceClassification.from_pretrained(model_ckpt_path).to(device)\n","    all_probs = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        enc = tokenizer(batch, padding=True, truncation=True,\n","                        max_length=max_length, return_tensors='pt').to(device)\n","        with torch.no_grad():\n","            logits = model(**enc).logits\n","        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n","        all_probs.append(probs)\n","    return np.vstack(all_probs)\n","\n","# 1) Carga datos de validación\n","reader = EXISTReader(\"EXIST2025_training.json\")\n","_, _, train_texts, train_labels = reader.get(lang=\"EN\", subtask=\"1\")\n","_, _, dev_texts, dev_labels = reader.get(lang=\"EN\", subtask=\"1\")\n","\n","# 2) Nombres de los checkpoints base que quieres ensayar\n","base_models = [\"roberta-base\", \"xlm-roberta-base\", \"microsoft/deberta-v3-base\"]\n","\n","# 3) Entrena cada LoRA y captura probabilidades en validación\n","dev_features = []\n","for m in base_models:\n","    # Fine-tune LoRA y fusiona pesos\n","    mix_model, _ = sexism_classification_pipeline_task1_LoRA(\n","        (None, train_texts, train_labels),\n","        (None, dev_texts, dev_labels),\n","        None,\n","        model_name=m,\n","        nlabels=2, ptype=\"single_label_classification\",\n","        output_dir=f\"./lora_{m}\"\n","    )  # :contentReference[oaicite:0]{index=0}\n","\n","    # mix_model es el modelo ya fusionado en memoria; guárdalo para reload si quieres:\n","    mix_model.save_pretrained(f\"./stacks/{m}\")\n","\n","    # Extrae probabilidades de validación\n","    probs = get_probs(f\"./stacks/{m}\", dev_texts)  # shape=(N_dev,2)\n","    # Tomamos solo la probabilidad de la clase “YES” (índice 1)\n","    dev_features.append(probs[:,1])\n","\n","# 4) Construye matriz de características y “meta-learner”\n","X_dev = np.stack(dev_features, axis=1)  # (N_dev, K)\n","y_dev = np.array([1 if lab==\"YES\" else 0 for lab in dev_labels])\n","\n","meta = LogisticRegression(max_iter=200)\n","meta.fit(X_dev, y_dev)\n","\n","# 5) Validación final\n","y_pred = meta.predict(X_dev)\n","print(\"F1 stacking (Task1):\", f1_score(y_dev, y_pred))\n"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import f1_score\n","from Tasks_LoRA_Pipelines import sexism_classification_pipeline_task3_LoRA\n","from readerEXIST2025 import EXISTReader\n","\n","# 1) Carga datos Task 3\n","reader = EXISTReader(\"EXIST2025_training.json\", task=3)\n","_, _, train_texts3, train_labels3 = reader.get(lang=\"EN\", subtask=\"3\")\n","_, _, dev_texts3, dev_labels3 = reader.get(lang=\"EN\", subtask=\"3\")\n","\n","# 2) Entrena un único LoRA y saca probabilidades (sigmoid)\n","mix3, _ = sexism_classification_pipeline_task3_LoRA(\n","    (None, train_texts3, train_labels3),\n","    (None, dev_texts3, dev_labels3),\n","    None,\n","    model_name='roberta-base',\n","    nlabels=6,\n","    ptype=\"multi_label_classification\",\n","    output_dir=\"./lora_task3\"\n",")  # :contentReference[oaicite:2]{index=2}\n","\n","# recarga y predice sobre validación:\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","tokenizer3 = AutoTokenizer.from_pretrained('roberta-base')\n","model3 = AutoModelForSequenceClassification.from_pretrained(\"./lora_task3\").to(device)\n","\n","# obtener logits y pasar por sigmoide\n","def get_multilabel_probs(model, tokenizer, texts, batch_size=32):\n","    all_probs=[]\n","    for i in range(0, len(texts), batch_size):\n","        batch = tokenizer(texts[i:i+batch_size], padding=True,\n","                          truncation=True, return_tensors='pt').to(device)\n","        with torch.no_grad():\n","            logits = model(**batch).logits\n","        all_probs.append(torch.sigmoid(logits).cpu().numpy())\n","    return np.vstack(all_probs)\n","\n","probs_dev3 = get_multilabel_probs(model3, tokenizer3, dev_texts3)  # (N_dev, 6)\n","y_true3   = np.array([ [1 if lab_i in lbls else 0\n","                         for lab_i in sorted({0,1,2,3,4,5})]\n","                       for lbls in dev_labels3 ])\n","\n","# 3) Búsqueda de umbral por etiqueta\n","def tune_thresholds(y_true, y_probs, n_steps=101):\n","    thresholds = np.linspace(0, 1, n_steps)\n","    best_ts = []\n","    for j in range(y_true.shape[1]):\n","        best_f1, best_t = -1, 0.5\n","        for t in thresholds:\n","            preds_j = (y_probs[:,j] >= t).astype(int)\n","            f1_j = f1_score(y_true[:,j], preds_j)\n","            if f1_j > best_f1:\n","                best_f1, best_t = f1_j, t\n","        best_ts.append(best_t)\n","    return best_ts\n","\n","best_thresholds = tune_thresholds(y_true3, probs_dev3)\n","print(\"Umbrales óptimos por etiqueta:\", best_thresholds)\n","\n","# 4) Aplicar en test\n","_, _, test_texts3 = reader.get(lang=\"EN\", subtask=\"3\")[:3]\n","probs_test3 = get_multilabel_probs(model3, tokenizer3, test_texts3)\n","preds_test3 = (probs_test3 >= best_thresholds).astype(int)\n"],"metadata":{"id":"EuwmQUrMDXWz"},"id":"EuwmQUrMDXWz","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pTu895HDDXS_"},"id":"pTu895HDDXS_","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}