{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbc961a",
   "metadata": {},
   "source": [
    "# LLMs Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3456ae7d",
   "metadata": {},
   "source": [
    "## PIPs and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB =True # IF YOU USE GOOGLE COLAB -> COLAB = True\n",
    "PIP = True # IF YOU NEED INSTALL LIBRARIES -> PIP = True\n",
    "\n",
    "if PIP:\n",
    "    !pip install transformers --upgrade\n",
    "    !pip install datasets accelerate\n",
    "    !pip install evaluate\n",
    "    !pip install -U PyEvALL\n",
    "\n",
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d92f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from pyevall.evaluation import PyEvALLEvaluation\n",
    "from pyevall.metrics.metricfactory import MetricFactory\n",
    "from pyevall.reports.reports import PyEvALLReport\n",
    "from pyevall.utils.utils import PyEvALLUtils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87445b",
   "metadata": {},
   "source": [
    "## Drive and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB is True:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  base_path = \"/content/drive/MyDrive/EXIST2025\"\n",
    "else:\n",
    "  base_path = \"..\"\n",
    "base_path\n",
    "\n",
    "library_path = base_path\n",
    "sys.path.append(library_path)\n",
    "from readerEXIST2025_2 import EXISTReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the dataset, adapt this path wherever you have the dataset\n",
    "dataset_path = os.path.join(base_path, \"Dataset/EXIST_2025_Dataset_V0.3/\")\n",
    "\n",
    "file_train = os.path.join(dataset_path, \"EXIST2025_training.json\")\n",
    "file_dev = os.path.join(dataset_path, \"EXIST2025_dev.json\")\n",
    "file_test = os.path.join(dataset_path, \"EXIST2025_test_clean.json\")\n",
    "\n",
    "\n",
    "reader_train = EXISTReader(file_train)\n",
    "reader_dev = EXISTReader(file_dev)\n",
    "reader_test = EXISTReader(file_test)\n",
    "\n",
    "\n",
    "EnTrainTask1, EnDevTask1, EnTestTask1 = reader_train.get(lang=\"EN\", subtask=\"1\"), reader_dev.get(lang=\"EN\", subtask=\"1\"), reader_test.get(lang=\"EN\", subtask=\"1\")\n",
    "EnTrainTask2, EnDevTask2, EnTestTask2 = reader_train.get(lang=\"EN\", subtask=\"2\"), reader_dev.get(lang=\"EN\", subtask=\"2\"), reader_test.get(lang=\"EN\", subtask=\"2\")\n",
    "EnTrainTask3, EnDevTask3, EnTestTask3 = reader_train.get(lang=\"EN\", subtask=\"3\"), reader_dev.get(lang=\"EN\", subtask=\"3\"), reader_test.get(lang=\"EN\", subtask=\"3\")\n",
    "\n",
    "\n",
    "SpTrainTask1, SpDevTask1, SpTestTask1  = reader_train.get(lang=\"ES\", subtask=\"1\"), reader_dev.get(lang=\"ES\", subtask=\"1\"), reader_test.get(lang=\"ES\", subtask=\"1\")\n",
    "SpTrainTask2, SpDevTask2, SpTestTask2  = reader_train.get(lang=\"ES\", subtask=\"2\"), reader_dev.get(lang=\"ES\", subtask=\"2\"), reader_test.get(lang=\"ES\", subtask=\"2\")\n",
    "SpTrainTask3, SpDevTask3, SpTestTask3  = reader_train.get(lang=\"ES\", subtask=\"3\"), reader_dev.get(lang=\"ES\", subtask=\"3\"), reader_test.get(lang=\"ES\", subtask=\"3\")\n",
    "\n",
    "!ls ../Dataset/EXIST_2025_Dataset_V0.3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d4b5f",
   "metadata": {},
   "source": [
    "## Import Code Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad752c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "functions_path = os.path.join(base_path, \"Functions\")\n",
    "\n",
    "for filename in os.listdir(functions_path):\n",
    "    if filename.endswith(\".py\") and not filename.startswith(\"__\"):\n",
    "        module_name = filename[:-3]\n",
    "        file_path = os.path.join(functions_path, filename)\n",
    "\n",
    "        # Cargar el m칩dulo\n",
    "        spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "\n",
    "        # Extraer todas las funciones del m칩dulo y cargarlas al espacio global\n",
    "        for name, func in inspect.getmembers(module, inspect.isfunction):\n",
    "            globals()[name] = func  # o locals()[name] si est치s dentro de una funci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\"meta-llama/Llama-2-7b-chat-hf\",\"meta-llama/Meta-Llama-3-70B\",\"meta-llama/Meta-Llama-3-8B\",\"gpt2\"]\n",
    "\n",
    "tokenizer,model = get_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados=[]\n",
    "for languaje in [\"En\", \"Sp\"]:\n",
    "  for task in [\"1\", \"2\", \"3\"]:\n",
    "    params = dict()\n",
    "    eval(f\"incontext_zero_pipeline_task{task}\")(model, tokenizer, eval(f\"{languaje}DevTask{task}\"), eval(f\"{languaje}TestTask{task}\"), eval(f\"output_postprocessing_incontext_zero_s{task}\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
